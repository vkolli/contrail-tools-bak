!/usr/bin/env bash
#!/usr/bin/awk -f
TOOLS_WS=${TOOLS_WS:-$(pwd)}
multi_node=0

#install ant on cfgm0
function install_fabric_cfgm() {
    
    sshpass -p "c0ntrail123" ssh root@$SM_SERVER_IP "sshpass -p ${API_SERVER_HOST_PASSWORD} scp -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null /root/sm_files/contrail_packages/setup.sh ${API_SERVER_HOST_STRING}:/opt/contrail/contrail_packages/"
    sshpass -p "c0ntrail123" ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null $API_SERVER_HOST_STRING " (
        set -x
        echo "Temporary workaround to installfabric on CFGM"
        /opt/contrail/contrail_packages/setup.sh
    ) "

}

function add_sourcelist() {

    HOSTS=`cat "${TOOLS_WS}/testbeds/${tb_filename}" | grep "host[0-9]\s\=" | awk '{print $3}' | awk -F'@' '{print $2}' | tr -d "'"`
    echo $HOSTS
    declare -a ARRAY_HOSTS
    i=0
    echo $i
    for word in $HOSTS
    do
        echo $word
        sshpass -p "c0ntrail123" ssh -l root -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null $word " {
   
            cp /etc/apt/sources.list /etc/apt/sources.list.orig
            cp /etc/apt/sources.list.save /etc/apt/sources.list
            if [ $? != 0 ]
                then
                echo "failed to replace sources.list with sources.list.save on node!!!"
            else
                echo "replaced sources.list with sources.list.save on node"
            fi
            
            #remove mediubuntu entry from sources.list temporarily as it's causing apt-get update to fail.
            sed -i".bak" '/packages.medibuntu.org/d' /etc/apt/sources.list

            apt-get update
            apt-get -y install gdb
            if [ $? != 0 ]
                then
                echo "failed to install gdb!!!"
            else
                echo "installed gdb successfully"
            fi
            if [ $API_SERVER_IP == $word ]; then
                apt-get -y --force-yes --allow-unauthenticated install ant
                #temporary fix to take care of issue due to different paramiko version
                pip uninstall -y paramiko
                pip install paramiko==1.17.0
            fi
            cp /etc/apt/sources.list.orig /etc/apt/sources.list
            apt-get update
    } "
        #This is a temporary patch, that needs to be removed once the multi interface setup is free from the mac-address issue seen on nodea4
        nodea4_ip="10.204.221.60"
        if [ $nodea4_ip == $word ]
            then
            echo "Restarting supervisor-vrouter service on nodea4."
            sshpass -p "c0ntrail123" ssh -l root -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null $word " {
                service supervisor-vrouter restart
                #a=0; while [ \$a -lt 15 ]; do result=`contrail-status | grep vrouter-agent | grep " active " | wc -l`; if [ \$result -eq 1 ]; then a=15; else a=`expr \$a + 1`; sleep 2; fi; done
            } "
        fi
    sleep 10
    done
}



#check if the server-manager pkgs are available in artifacts folder.
function check_SM_pkg_availability() {
    count=0
    if [ $SM_TYPE -eq 1 ] 
    then
        pkg_dir="/cs-shared/github-build/${BRANCH}/${BUILDID}/ubuntu-14-04/${SKU}/artifacts"
    else
        pkg_dir="/cs-shared/github-build/${BRANCH}/${BUILDID}/centos64_os/${SKU}/artifacts"
    fi
    
    while [ "$count" -ne 36 ]; do
        if ls $pkg_dir/contrail-server-manager-installer*
        then
            echo "SM pkgs are present in artifacts"
            break
        else
            if [ "$count" -eq 35 ]
            then
                echo "waited for an hour, still pkgs are not found, aborting"
                exit 1
            fi
            echo "SM pkgs are still not there, let's wait..."
            sleep 100
            count=$((count+1))
        fi
    done
}

#upgrade/install SM on either cenots/ubuntu server.
#Multi-node setup will refer to SM running on ubuntu
#Single-node setup will refer to SM running on centos
function bringup_SM_setup() {
    if [ $SKIP_BRINGUP -ne 0 ]
    then
        return 0
    fi

    echo "Bringup/upgrade SM setup"

    #check if SM pkgs are available in artifacts before proceeding further.
    check_SM_pkg_availability || die "SM pkg not available in artifacts"

    cd $pkg_dir

    #SM pkg name is different for centos & ubuntu, so set it accordingly.
    #multi-node uses ubuntu SM and single node uses centos SM.
    if [ $SM_TYPE -eq 1 ] #if multi node refer to ubuntu folder
    then
        SM_SERVER_PKG_FILE=`ls contrail-server-manager-installer_*\.*-${BUILDID}\~$SKU\_all.deb*`
    else
        SM_SERVER_PKG_FILE=`ls contrail-server-manager-installer-*\.*-${BUILDID}*.el6.noarch.rpm*`
        echo $SM_SERVER_PKG_FILE
    fi
    pkg_name="$pkg_dir/$SM_SERVER_PKG_FILE"

    sshpass -p "c0ntrail123" ssh -l root -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null $SM_SERVER_IP " (
        mkdir /root/sm_files/
    ) " 
    
    sshpass -p "c0ntrail123" scp -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null root@$BASE_CLUSTER:/root/${TEMPLATE_DIR}/*.json ${TOOLS_WS}/sm_files/ 
    #Copy install and provision check shell scripts
    sshpass -p "c0ntrail123" scp -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null ${TOOLS_WS}/sm_files/* root@$SM_SERVER_IP:/root/sm_files/
    #copy the SM PKGs to SM server.
    sshpass -p "c0ntrail123" scp -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null $pkg_name root@$SM_SERVER_IP:/root/sm_files/

    echo "Connect to SM_SERVER to install/upgrade SM packages"
    sshpass -p "c0ntrail123" ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -l root $SM_SERVER_IP " (
        set -e
        echo "127.0.1.1 servermanager.englab.juniper.net servermanager" >> /etc/hosts
        if [ -e /root/sm_files/$SM_SERVER_PKG_FILE ] 
        then
            echo "file exists, upgrading Server manager"
            cd /root/sm_files; 
            if [ $SM_TYPE -eq 1 ]
            then
                ./ubuntu_smgr_purge_and_install.sh $SM_SERVER_PKG_FILE
            else
                ./centos_smgr_upgrade.sh $SM_SERVER_PKG_FILE
            fi
            if [ $? != 0 ] 
            then
                echo "upgrade/installation of server-manager failed, aborting the process"
                exit 1
            fi

            sleep 1
            echo "check if SM has been installed by following checks"
            sleep 30

            netstat -nap | grep 9001
            if [ $? != 0 ]
            then
                echo "Server Manager pkg installation failed!!!"
                exit 1
            else
                echo "Server Manager pkg installed successfully"
            fi

            echo "check if SM client installed"
            if [ -e /usr/bin/server-manager ]
            then
                echo "SM client installed successfully"
            else
                echo "SM client pkg installion failed"
                exit 1
            fi
            sleep 1
        else
            echo "SM PKGs not present in the folder, aborting the process"
            exit 1
        fi

        echo "Installation is fine, delete the images from the server"
        #rm $SM_SERVER_PKG_FILE
    ) "
}

# This function will provision the provided setup using cliff client.
function provision_using_SM_cliff_client() {
    if [ $SKIP_SM_PROVISION -ne 0 ]
    then
        return 0
    fi

    echo "Connect to SM_SERVER to provision the targets/cluster"
    sshpass -p "c0ntrail123" ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -l root $SM_SERVER_IP " (
        set -e
        echo "provision the target setup"
        server-manager-client provision -F --cluster_id $CLUSTER_NAME $SMID
        if [ $? == 0 ]
        then
            echo "Server-manager provision command is successful"
        else
            echo "Server-manager provision command failed, aborting the process"
            exit 1
        fi
        echo "provisioning in progress please wait ..."
        sleep 100

        #check provisioing status.
        /root/sm_files/check_provision_cliff.sh $CLUSTER_NAME
        if [ $? == 0 ]
        then
            echo "Provisioning of the target/cluster is sucessfull!!!"
        else
            echo "Provisioning of the target/cluster failed!!! aborting the process"
            exit 1
        fi

        server-manager-client status server --cluster_id $CLUSTER_NAME

    ) "
    if [ $? == 0 ]
    then
        echo "Provisioning of the target/cluster is sucessfull!!!"
        sleep 120
    else
        echo "Provisioning of the target/cluster failed!!! aborting the process"
        exit 1
    fi

}

# This function will provision the provided setup.
function provision_using_SM() {
    if [ $SKIP_SM_PROVISION -ne 0 ]
    then
        return 0
    fi
   
    echo "Connect to SM_SERVER to provision the targets/cluster"
    sshpass -p "c0ntrail123" ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -l root $SM_SERVER_IP " (
        set -e
        echo "provision the target setup"
        server-manager provision -F --cluster_id $CLUSTER_NAME $SMID
        if [ $? == 0 ]
        then
            echo "Server-manager provision command is successful"
        else
            echo "Server-manager provision command failed, aborting the process"
            exit 1
        fi
        echo "provisioning in progress please wait ..."
        sleep 100

        #check provisioing status.
        /root/sm_files/check_provision.sh $CLUSTER_NAME
        if [ $? == 0 ]
        then
            echo "Provisioning of the target/cluster is sucessfull!!!"
        else
            echo "Provisioning of the target/cluster failed!!! aborting the process"
            exit 1
        fi

        server-manager status server --cluster_id $CLUSTER_NAME --detail

    ) "
    if [ $? == 0 ]
    then
        echo "Provisioning of the target/cluster is sucessfull!!!"
        sleep 120
    else
        echo "Provisioning of the target/cluster failed!!! aborting the process"
        exit 1
    fi

}

# This function will delete contrail package with same id from SM using cliff client.
function delete_pkg_from_SM_cliff_client() {
    if [ $SKIP_PKG_DELETE_SM -ne 0 ]
    then
        return 0
    fi
    echo "Connect to SM_SERVER to delete the package and cleanup."
    sshpass -p "c0ntrail123" ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -l root $SM_SERVER_IP " (
        set -e
        echo "delete the package"
        server-manager-client delete image --image_id $SMID
    ) "
    if [ $? == 0 ]
    then
        echo "Deletion of the package from the SM node is sucessfull!!!"
        sleep 10
    else
        echo "Deletion of the package from the SM node failed!!! aborting the process"
        echo "Must delete stray packages manually."
    fi
}

# This function will provision the provided setup.
function delete_pkg_from_SM() {
    if [ $SKIP_PKG_DELETE_SM -ne 0 ]
    then
        return 0
    fi
    echo "Connect to SM_SERVER to delete the package and cleanup."
    sshpass -p "c0ntrail123" ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -l root $SM_SERVER_IP " (
        set -e
        echo "delete the package"
        if [ ${BRANCH} == "R1.10" ]
        then
            server-manager delete image $SMID
        else
            server-manager delete image --image_id $SMID
        fi
    ) "
    if [ $? == 0 ]
    then
        echo "Deletion of the package from the SM node is sucessfull!!!"
        sleep 10
    else
        echo "Deletion of the package from the SM node failed!!! aborting the process"
        echo "Must delete stray packages manually."
    fi
}

# This function will reimage the provided setup using SM cliff client.
# Performs the following steps:
# Adds the iso and contrail packages to SM database
# Adds cluster and servers to SM database
# Does reimage of the setup.
function reimage_using_SM_cliff_client() {
    if [ $SKIP_REIMAGE -ne 0 ]
    then
        return 0
    fi
    # set the parameters required for reimage.
    if [[ $DISTRO =~ ubuntu-12.04 ]]; then
        image="/cs-shared/images/ubuntu-12.04.3-server-amd64.iso"
        pkg_type="contrail-ubuntu-package"
        iso_type="ubuntu"
        SMID=ubuntu12$SKU${BUILDID}
    elif [[ $DISTRO =~ ubuntu-14.04 ]]; then
        image="/cs-shared/images/ubuntu-14.04.5-server-amd64.iso"
        pkg_type="contrail-ubuntu-package"
        iso_type="ubuntu"
        SMID=ubuntu14$SKU${BUILDID}
        isofile="/root/images/image145.json"
    elif [[ $DISTRO =~ centos64 ]]; then
        image="/root/images/CentOS-6.4-x86_64-minimal.iso"
        pkg_type="contrail-centos-package"
        iso_type="centos"
        SMID=centos64$SKU${BUILDID}
    elif [[ $DISTRO =~ centos65 ]]; then
        image="/root/images/CentOS-6.5-x86_64-minimal.iso"
        pkg_type="contrail-centos-package"
        iso_type="centos"
        SMID=centos65$SKU${BUILDID}
    elif [[ ${CENTOS_72} -eq 1 ]];then
	image="/root/images/CentOS-7-x86_64-Minimal-1511.iso"
	pkg_type="contrail-centos-package"
	iso_type="redhat"
	SMID=centos72$SKU${BUILDID}
	contrail_pkg=`ls /cs-shared/github-build/${BRANCH}/${BUILDID}/${DISTRO}/${SKU}/contrail-install-packages*.rpm`
        isofile="/root/images/centos72.json"
    elif [[ $DISTRO =~ centos71 ]]; then
        image="/root/images/CentOS-7-x86_64-Minimal-1503-01.iso"
        pkg_type="contrail-centos-package"
        iso_type="redhat"
        SMID=centos71$SKU${BUILDID}
        contrail_pkg=`ls /cs-shared/github-build/${BRANCH}/${BUILDID}/${DISTRO}/${SKU}/contrail-install-packages*.rpm`
	isofile="/root/images/centos71.json"
    fi

    pkg_path="/cs-shared/github-build/${BRANCH}/${BUILDID}/${DISTRO}/${SKU}/"
    if [ $USE_CLOUD_PKG -eq 1 ]; then
        contrail_pkg=`ls /cs-shared/github-build/${BRANCH}/${BUILDID}/${DISTRO}/${SKU}/contrail-install-packages*.tgz`
    else
        if [[ $DISTRO =~ centos71 ]]; then
            contrail_pkg=`ls /cs-shared/github-build/${BRANCH}/${BUILDID}/${DISTRO}/${SKU}/contrail-install-packages*.rpm`
        else
            contrail_pkg=`ls /cs-shared/github-build/${BRANCH}/${BUILDID}/${DISTRO}/${SKU}/contrail-install-packages*.deb`
        fi
    fi

    echo ${contrail_pkg}
    echo ${pkg_path}
    #set the parameters for multi/single node setup
    CLUSTER_FILE_NAME=${CLUSTER_FILE_NAME}_new_param
    SERVER_FILE_NAME=${SERVER_FILE_NAME}_new_param
    echo "Using NEW parameters for cluster and server json files."
    if [[ $DISTRO =~ ubuntu-14.04 ]]; then
    cluster_json="/root/sm_files/$CLUSTER_FILE_NAME.json"
    server_json="/root/sm_files/$SERVER_FILE_NAME.json"
    else
    # set the cluster,server json for centos
    CLUSTER_FILE_NAME=${CLUSTER_FILE_NAME}_centos
    SERVER_FILE_NAME=${SERVER_FILE_NAME}_centos
    cluster_json="/root/sm_files/$CLUSTER_FILE_NAME.json"
    server_json="/root/sm_files/$SERVER_FILE_NAME.json"
    fi

    echo "Connect to SM_SERVER to reimage and provision the targets"
    sshpass -p "c0ntrail123" ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -l root $SM_SERVER_IP " (
        set -e
        echo "add required image/server/cluster for reimage and provision of the target"

        echo "delete iso image if it exists"
        server-manager-client delete image --image_id ${DISTRO}

        echo "add base ISO image to server manager database"
        server-manager-client upload-image --id ${DISTRO} --version ${BUILDID} --category image --type $iso_type --file_name ${isofile}
        if [ $? == 0 ]
        then
            echo "Server-manager adding image command is successful"
        else
            echo "Server-manager adding image command failed, aborting the process"
            exit 1
        fi

        echo "check if the image was added successfully"
        server-manager-client display image --json | grep ${DISTRO}
        if [ $? != 0 ]
        then
            echo "Adding Base ISO image failed"
            exit 1
        fi

        echo "delete contrail package if it exists"
        server-manager-client delete image --image_id $SMID
        echo "add contrail package to the SM database"

        server-manager-client upload-image --id $SMID --version ${BUILDID} --category package --type $pkg_type --file_name ${contrail_pkg}
        if [ $? == 0 ]
        then
            echo "Server-manager adding contrail-package command is successful"
        else
            echo "Server-manager adding contrail-package command failed, aborting the process"
            exit 1
        fi

        echo "check if the package was added successfully"
        server-manager-client display image --json | grep $SMID
        if [ $? != 0 ]
        then
            echo "Adding Contrail-packages $SMID failed"
            exit 1
        fi

        server-manager-client display image

        echo "Clean up cluster and server from SM database before adding."
        server-manager-client delete server --cluster_id $CLUSTER_NAME
        server-manager-client delete cluster --cluster_id $CLUSTER_NAME

        echo "add cluster to SM database"
        server-manager-client add cluster -f $cluster_json
        if [ $? == 0 ]
        then
            echo "Adding cluster to server-manager is sucessful!!!"
        else
            echo "Adding cluster to server-manager failed, aborting the process"
            exit 1
        fi

        server-manager-client display cluster --detail

        echo "add server to SM database"
        server-manager-client add server -f $server_json
        if [ $? == 0 ]
        then
            echo "Adding server to server-manager is sucessful!!!"
        else
            echo "Adding server to server-manager failed, aborting the process"
            exit 1
        fi

        server-manager-client display server --detail

        echo "reimage the target setup"
        server-manager-client reimage -F --cluster_id $CLUSTER_NAME ${DISTRO}
        if [ $? == 0 ]
        then
            echo "Issue of Reimage command to reimage target nodes is sucessful!!!"
        else
            echo "Issue of Reimage command to reimage target nodes failed, aborting the process"
            exit 1
        fi

        echo "reimage in progress please wait ..."
        sleep 10

        #check if reimage is completed.
        /root/sm_files/check_reimage_cliff.sh $CLUSTER_NAME
        if [ $? == 0 ]
        then
            echo "reimaged the target $CLUSTER_NAME successfully"
        else
            echo "reimage of target $CLUSTER_NAME failed!!!"
            exit 1
        fi

    ) "
    if [ $? == 0 ]
    then
        echo "reimaged the target $CLUSTER_NAME successfully"
        sleep 150
    else
        echo "reimage of target $CLUSTER_NAME failed!!!"
        exit 1
    fi


}

# This function will reimage the provided setup.
# Performs the following steps:
# Adds the iso and contrail packages to SM database
# Adds cluster and servers to SM database
# Does reimage of the setup.
function add_server_cluster_SM() {
    if [ $SKIP_REIMAGE -ne 0 ]
    then
        return 0
    fi

    if [ $SMLITE_REGRESSION -eq 0 ]
    then
        # set the parameters required for reimage.
        if [[ $DISTRO =~ ubuntu-12.04 ]]; then
            image="/cs-shared/images/ubuntu-12.04.3-server-amd64.iso" 
            pkg_type="contrail-ubuntu-package"
            iso_type="ubuntu"
            SMID=ubuntu12$SKU${BUILDID}
        elif [[ $DISTRO =~ ubuntu-14.04 ]]; then 
            image="/cs-shared/images/ubuntu-14.04.5-server-amd64.iso"
            pkg_type="contrail-ubuntu-package"
            iso_type="ubuntu"
            SMID=ubuntu14$SKU${BUILDID}
            iso_name="ubuntu-14-04"
            isofile="/root/sm_files/image145.iso"
        elif [[ $DISTRO =~ centos64 ]]; then 
            image="/root/images/CentOS-6.4-x86_64-minimal.iso"
            pkg_type="contrail-centos-package"
            iso_type="centos"
            SMID=centos64$SKU${BUILDID}
        elif [[ $DISTRO =~ centos65 ]]; then 
            image="/root/images/CentOS-6.5-x86_64-minimal.iso"
            pkg_type="contrail-centos-package"
            iso_type="centos"
            SMID=centos65$SKU${BUILDID}
        elif [[ ${CENTOS_72} -eq 1 ]];then
            image="/root/images/CentOS-7-x86_64-Minimal-1511.iso"
            pkg_type="contrail-centos-package"
            iso_type="redhat"
            iso_name=${DISTRO}
            SMID=centos72$SKU${BUILDID}
            contrail_pkg=`ls /cs-shared/github-build/${BRANCH}/${BUILDID}/${DISTRO}/${SKU}/contrail-install-packages*.rpm`
            isofile="/root/sm_files/centos72.json"
        elif [[ $DISTRO =~ centos71 ]]; then
            image="/root/images/CentOS-7-x86_64-Minimal-1503-01.iso"
            pkg_type="contrail-centos-package"
            iso_type="redhat"
            SMID=centos71$SKU${BUILDID}
            contrail_pkg=`ls /cs-shared/github-build/${BRANCH}/${BUILDID}/${DISTRO}/${SKU}/contrail-install-packages*.rpm`
            isofile="/root/sm_files/centos71.json"
        fi
    
        pkg_path="/cs-shared/github-build/${BRANCH}/${BUILDID}/${DISTRO}/${SKU}/"
        cd $pkg_path
        if [ $USE_CLOUD_PKG -eq 1 ]; then
            contrail_pkg=`ls /cs-shared/github-build/${BRANCH}/${BUILDID}/${DISTRO}/${SKU}/contrail-install-packages*.tgz`
            contrail_pkg_name=`ls contrail-install-packages*.tgz`
        else
            if [[ $DISTRO =~ centos71 ]]; then
                contrail_pkg=`ls /cs-shared/github-build/${BRANCH}/${BUILDID}/${DISTRO}/${SKU}/contrail-install-packages*.rpm`
                contrail_pkg_name=`ls contrail-install-packages*.rpm`
            else
                contrail_pkg=`ls /cs-shared/github-build/${BRANCH}/${BUILDID}/${DISTRO}/${SKU}/contrail-install-packages*.deb`
                contrail_pkg_name=`ls contrail-install-packages*.deb`
            fi
        fi

        echo ${contrail_pkg}
        echo ${pkg_path} 

        #SM pkg name is different for centos & ubuntu, so set it accordingly.
        #multi-node uses ubuntu SM and single node uses centos SM.
        #set the parameters for multi/single node setup
        cluster_json="/root/sm_files/cluster.json"
        server_json="/root/sm_files/server.json"
        sshpass -p "c0ntrail123" scp -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null ${contrail_pkg} root@$SM_SERVER_IP:/root/sm_files/
        sshpass -p "c0ntrail123" scp -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null ${image} root@$SM_SERVER_IP:${isofile}
    
        echo "Connect to SM_SERVER to reimage and provision the targets"
        sshpass -p "c0ntrail123" scp -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null ${TOOLS_WS}/sm_files/preconfig.py root@$SM_SERVER_IP:/opt/contrail/server_manager/client/preconfig.py
        sshpass -p "c0ntrail123" ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -l root $SM_SERVER_IP " (
            set -e
            echo "add required image/server/cluster for reimage and provision of the target"
            cd /root/sm_files 

            set -e
            echo "add required image/server/cluster for reimage and provision of the target"

            echo "delete iso image if it exists"
            server-manager-client delete image --image_id ${iso_name}

            echo "add base ISO image to server manager database"
            echo "add base ISO image to server manager database"
            server-manager-client upload-image --id ${iso_name} --version ${BUILDID} --category image --type ${iso_type} --file_name ${isofile}
            if [ $? == 0 ]
            then
                echo "Server-manager adding image command is successful"
            else
                echo "Server-manager adding image command failed, aborting the process"
                exit 1
            fi

            echo "check if the image was added successfully"
            server-manager-client display image --json | grep ${iso_name}
            if [ $? != 0 ]
            then
                echo "Adding Base ISO image failed"
                exit 1
            fi

            echo "delete contrail package if it exists"
            if [ ${BRANCH} == "R1.10" ]
            then
                server-manager delete image $SMID
            else
                server-manager delete image --image_id $SMID
            fi
            echo "add contrail package to the SM database"
          
            server-manager upload_image $SMID ${BUILDID} $pkg_type $contrail_pkg_name
            if [ $? == 0 ]
            then
                echo "Server-manager adding contrail-package command is successful"
            else
                echo "Server-manager adding contrail-package command failed, aborting the process"
                exit 1
            fi
    
            echo "check if the package was added successfully"
            server-manager show image | grep $SMID
            if [ $? != 0 ] 
            then
                echo "Adding Contrail-packages $SMID failed"
                exit 1
            fi
    
            server-manager show image
    
            echo "Clean up cluster and server from SM database before adding."
            server-manager delete server --cluster_id $CLUSTER_NAME
            server-manager delete cluster --cluster_id $CLUSTER_NAME
    
            echo "add cluster to SM database"
            server-manager add cluster -f $cluster_json
            if [ $? == 0 ]
            then
                echo "Adding cluster to server-manager is sucessful!!!"
            else
                echo "Adding cluster to server-manager failed, aborting the process"
                exit 1
            fi
    
            server-manager show cluster --detail
    
            echo "add server to SM database"
            server-manager add server -f $server_json
            if [ $? == 0 ]
            then
                echo "Adding server to server-manager is sucessful!!!"
            else
                echo "Adding server to server-manager failed, aborting the process"
                exit 1
            fi
            echo "Preconfigure the servers"
            python /opt/contrail/server_manager/client/preconfig.py --server-json $server_json  --server-manager-ip $SM_SERVER_IP --server-manager-repo-port 80    
            if [ $? == 0 ]
            then
                echo "Preconfigure server through server-manager is sucessful!!!"
            else
                echo "Preconfigure server through server-manager failed, aborting the process"
                exit 1
            fi            
        ) "
    fi

    if [ $? == 0 ]
    then
        echo "Added server to cluster $CLUSTER_NAME successfully"
        sleep 150
    else
        echo "Added server to cluster $CLUSTER_NAME failed!!!"
        exit 1
    fi
    
   
}

function check_kernel_upgrade() {
    echo "Checking for kernel version upgrade."
    sshpass -p $SM_SERVER_PASSWORD ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -l root $SM_SERVER_IP " (
        set -e
        /root/sm_files/check_kernel_version.py
        if [ $? == 0 ]
        then
            echo "Kernel version upgrade is sucessful!!!"
        else
            echo "Kernel version upgrade failed, aborting the process"
            exit 1
        fi
    ) "

    if [ $? == 0 ]
    then
        echo "Kernel version upgrade is sucessful!!!"
    else
        echo "Kernel version upgrade failed!!!"
        exit 1
    fi
}

function launch_testbed_virtual() {
    echo "Launch testbed using heat template"
    sshpass -p "c0ntrail123" ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -l root $BASE_CLUSTER " (
        set -e
        mkdir /root/${TEMPLATE_DIR}/
    ) "
    sshpass -p "c0ntrail123" scp -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null ${TOOLS_WS}/templates/* root@$BASE_CLUSTER:/root/${TEMPLATE_DIR}/
    sshpass -p "c0ntrail123" ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -l root $BASE_CLUSTER " (
        set -e
        cp /root/${TEMPLATE_DIR}/$TEMPLATE /root/${TEMPLATE_DIR}/input.json
        cd /root/${TEMPLATE_DIR}/
        ./build_infra.sh ${TEMPLATE_DIR} "U14_04_5"
        if [ $? == 0 ]
        then
            echo "Launch of Virtual testbed was successful!!!"
        else
            echo "Launch of virtual testbed failed, aborting"
            exit 1
        fi
    ) "
    sshpass -p "c0ntrail123" scp -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null root@$BASE_CLUSTER:/root/${TEMPLATE_DIR}/server-manager-file ${TOOLS_WS}/
    export SM_SERVER_IP=`cat ${TOOLS_WS}/server-manager-file`
    sshpass -p "c0ntrail123" scp -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null root@$BASE_CLUSTER:/root/${TEMPLATE_DIR}/config-node-ip ${TOOLS_WS}/
    export API_SERVER_HOST_STRING="root@"`cat ${TOOLS_WS}/config-node-ip`
    sshpass -p "c0ntrail123" scp -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null root@$BASE_CLUSTER:/root/${TEMPLATE_DIR}/info.txt ${TOOLS_WS}/
    sshpass -p "c0ntrail123" scp -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null root@$BASE_CLUSTER:/root/${TEMPLATE_DIR}/testbed.py ${TOOLS_WS}/testbeds/$TBFILE
}

function delete_stacks() {
    sshpass -p "c0ntrail123" ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -l root $BASE_CLUSTER " (
        set -e
        cd /root/${TEMPLATE_DIR}/
        ./delete_stack.sh info.txt 
    )"
}

function run_smgr_virtual_task() {
    echo "Running tests on $1.."
    #New Function
    export TEMPLATE_DIR=${SCRIPT_TIMESTAMP}
    export TBFILE="template_HA.py"    
    export TBFILE_NAME="template_HA.py"
    launch_testbed_virtual || debug_and_die "Failed to launch testbed setup"
    echo $SM_SERVER_IP
    if [ ${TEST_SETUP} == "SINGLENODE" ]
    then
        multi_node=0
    elif [ ${TEST_SETUP} == "MULTINODE" ]
    then
        multi_node=1
    elif [ ${TEST_SETUP} == "MULTIINTERFACE" ]
    then
        multi_node=1
        CLUSTER_NAME="test-cluster"
    else
        echo "TEST_SETUP is not defined, abort the process"
        exit 1
    fi
    if [ -z "$SM_SERVER_IP" ]
    then
        echo "SM_SERVER_IP is not set, unable to proceede, aborting the process"
        exit 1
    fi

    if [ -z $CLUSTER_NAME ]; then
        echo "CLUSTER_NAME env is not set, aborting the process"
        exit 1
    fi
    create_testbed || die "Failed to create required testbed details"
    bringup_SM_setup || debug_and_die "Failed to bringup SM setup"

    add_server_cluster_SM || debug_and_die "Failed to add server and cluster to SM"

    if [[ ( ${BRANCH} > "R2.23" ) || ( ${BRANCH} == "mainline" ) ]]
    then
        provision_using_SM_cliff_client || debug_and_die "provision failed"
    else
        provision_using_SM || debug_and_die "provision failed"
    fi
    check_kernel_upgrade || die "kernel upgrade failed"
    
    if [[ $TEST_RUN_INFRA == 'docker' ]]; then
        search_package
        pkg_file_name=`basename $PKG_FILE`
        if [[ $USE_CLOUD_PKG -eq 1 || $USE_NETWORKING_PKG -eq 1 ]]; then
            export PACKAGE_VERSION=`echo ${pkg_file_name} | sed 's/contrail-installer-packages[-_]\([0-9\.\-]*\).*/\1/'`
        else
            export PACKAGE_VERSION=`echo ${pkg_file_name} | sed 's/contrail-install-packages[-_]\([0-9\.\-]*\).*/\1/'`
        fi
        if [[ -z $TEST_HOST_STRING ]]; then
            export TEST_HOST_STRING=$API_SERVER_HOST_STRING
            export TEST_HOST_PASSWORD=$API_SERVER_HOST_PASSWORD
        fi
        export TEST_HOST_IP=`echo $TEST_HOST_STRING | cut -d @ -f2`
        export TEST_HOST_USER=`echo $TEST_HOST_STRING | cut -d @ -f1`
        #Edit testbed_file
        sshpass -p "c0ntrail123" scp -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null root@$BASE_CLUSTER:/root/${TEMPLATE_DIR}/testbed.py ${TOOLS_WS}/testbeds/${tb_filename}
        #cp {TOOLS_WS}/testbeds/${tb_filename} {TOOLS_WS}/testbeds/${tb_filename}_back
        #echo `python ${TOOLS_WS}/templates/change_testbed_params.py ${TOOLS_WS}/templates/${$TEMPLATE} ${TOOLS_WS}/testbeds/${tb_filename} change_testbed_params`
        #python ${TOOLS_WS}/templates/change_testbed_params.py ${TOOLS_WS}/templates/${TEMPLATE} ${TOOLS_WS}/testbeds/${tb_filename} change_testbed_params
        setup_testnode || debug_and_die "test node setup failed"
        install_dep_pkgs_for_test
        run_sanity_simple || debug_and_die "run_sanity_simple failed"
    else
        add_sourcelist || die "source.list copy failed on all target nodes"
        install_third_party_pkgs || die "installing GDB/ant failed"
        install_dep_pkgs_for_test
        run_sanity || debug_and_die "Run_sanity step failed"
    fi

    run_tempest || die "Run_Tempest step failed"
    collect_tech_support || die "Task to collect logs/cores failed"
    delete_stacks || die "Failed to delete stacks"
    echo "Ending test on $1"
}


function debug_and_die
{
    local message=$1
    if [ $LOCK_TESTBED_ON_FAILURE -eq 1 ]; then
        echo "Testbed is set to be locked on failure and add stack info to lock file"
        cat ${TOOLS_WS}/info.txt >> ${LOCK_FILE_DIR}/${TBFILE_NAME}
        if [[ $message =~ 'Test failures exceed' ]]; then
            collect_tech_support
        fi
        export RELEASE_TESTBED=0
        lockfile ${LOCK_FILE_DIR}/lockfile1

        set -x
        echo "Locking testbed $tb_lock_file for debugging"
        echo "Testbed locked..Unlock when debug complete" >> $tb_lock_file
        cat $tb_lock_file

        remove_lock_file
    else
        collect_tech_support
        echo "Testbed stack delete!!!"
        delete_stacks || die "Failed to delete stacks"
        if [[ $VCENTER_ONLY_TESTBED -eq 1  || $VCENTER_AS_COMPUTE_TESTBED -eq 1 ]]; then
            # deregister the setup from vcenter server
            run_fab cleanup_vcenter
        fi
    fi
    [ -z "$message" ] && message="Died"
    echo "${BASH_SOURCE[1]}: line ${BASH_LINENO[0]}: ${FUNCNAME[1]}: $message." >&2
    cat $tb_lock_file
    python ${TOOLS_WS}/testers/upload.py --pkg_name $PKG_FILE --jenkins_id $SCRIPT_TIMESTAMP
    exit 1
}

function cleanup() {
    if [ $LOCK_TESTBED_ON_FAILURE -eq 0 ]; then
        delete_stacks || die "Failed to delete stacks"
    else
        cat ${TOOLS_WS}/info.txt >> ${LOCK_FILE_DIR}/${TBFILE_NAME}     
    fi
    unlock_testbed $TBFILE_NAME || die "Failed to unlock testbed $TBFILE_NAME"
}
